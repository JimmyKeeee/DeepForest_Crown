{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forest: Sensors\n",
    "\n",
    ":::{note}\n",
    "Under construction\n",
    "\n",
    "Source: Pyviz Topics - [Carbon Monitoring Project](https://github.com/pyviz-topics/examples/blob/c26bf42101b53a6c356fcd5b3a784b07d6178940/carbon_flux/carbon_flux.ipynb)\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip -q install s3fs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip -q install geoviews"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%writefile catalog.yaml\n",
    "sources:\n",
    "  fluxnet_daily:\n",
    "    driver: csv\n",
    "    parameters:\n",
    "      s3_path:\n",
    "        description: Filename to load\n",
    "        type: str\n",
    "        default: earth-data/carbon_flux/nee_data_fusion/FLX_AR-SLu_FLUXNET2015_FULLSET_DD_2009-2011_1-3.csv\n",
    "    cache:\n",
    "      - argkey: urlpath\n",
    "        regex: 'earth-data'\n",
    "        type: file\n",
    "    args:\n",
    "      urlpath: \"s3://{{ s3_path }}\"\n",
    "      path_as_pattern: 'FLX_{site}_FLUXNET2015_FULLSET_DD_{}.csv'\n",
    "      csv_kwargs:\n",
    "        assume_missing: true\n",
    "        na_values: [-9999]\n",
    "        parse_dates: ['TIMESTAMP']\n",
    "      storage_options: {'anon': True}\n",
    "\n",
    "  fluxnet_metadata:\n",
    "    driver: csv\n",
    "    cache:\n",
    "      - argkey: urlpath\n",
    "        regex: 'earth-data'\n",
    "        type: file\n",
    "    args:\n",
    "      urlpath: \"s3://earth-data/carbon_flux/nee_data_fusion/allflux_metadata.txt\"\n",
    "      csv_kwargs:\n",
    "        header: null\n",
    "        names: ['site', 'lat', 'lon', 'igbp', 'network']\n",
    "        usecols: ['site', 'lat', 'lon', 'igbp']\n",
    "      storage_options: {'anon': True}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import dask\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import holoviews as hv\n",
    "\n",
    "import hvplot.pandas\n",
    "import geoviews.tile_sources as gts\n",
    "\n",
    "pd.options.display.max_columns = 10\n",
    "hv.extension('bokeh', width=120)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import intake\n",
    "\n",
    "cat = intake.open_catalog('catalog.yaml')\n",
    "list(cat)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata = cat.fluxnet_metadata().read()\n",
    "metadata.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "igbp_vegetation = {\n",
    "    'WAT': '00 - Water',\n",
    "    'ENF': '01 - Evergreen Needleleaf Forest',\n",
    "    'EBF': '02 - Evergreen Broadleaf Forest',\n",
    "    'DNF': '03 - Deciduous Needleleaf Forest',\n",
    "    'DBF': '04 - Deciduous Broadleaf Forest',\n",
    "    'MF' : '05 - Mixed Forest',\n",
    "    'CSH': '06 - Closed Shrublands',\n",
    "    'OSH': '07 - Open shrublands',\n",
    "    'WSA': '08 - Woody Savannas',\n",
    "    'SAV': '09 - Savannas',\n",
    "    'GRA': '10 - Grasslands',\n",
    "    'WET': '11 - Permanent Wetlands',\n",
    "    'CRO': '12 - Croplands',\n",
    "    'URB': '13 - Urban and Built-up',\n",
    "    'CNV': '14 - Cropland/Nartural Vegetation Mosaics',\n",
    "    'SNO': '15 - Snow and Ice',\n",
    "    'BSV': '16 - Baren or Sparsely Vegetated'\n",
    "}\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "dtype = CategoricalDtype(ordered=True, categories=sorted(igbp_vegetation.values()))\n",
    "metadata['vegetation'] = (metadata['igbp']\n",
    "                          .apply(lambda x: igbp_vegetation[x])\n",
    "                          .astype(dtype))\n",
    "metadata.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "metadata.hvplot.points('lon', 'lat', geo=True, color='vegetation',\n",
    "                       height=420, width=800, cmap='Category20') * gts.OSM"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Loading FluxNet data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "data_columns = ['P_ERA', 'TA_ERA', 'PA_ERA', 'SW_IN_ERA', 'LW_IN_ERA', 'WS_ERA',\n",
    "                'VPD_ERA', 'TIMESTAMP', 'site', 'NEE_CUT_USTAR50']\n",
    "soil_data_columns = ['SWC_F_MDS_1', 'SWC_F_MDS_2', 'SWC_F_MDS_3',\n",
    "                     'TS_F_MDS_1', 'TS_F_MDS_2', 'TS_F_MDS_3']\n",
    "\n",
    "keep_from_csv = data_columns + soil_data_columns\n",
    "\n",
    "y_variable = 'NEE_CUT_USTAR50'\n",
    "\n",
    "def season(df, metadata):\n",
    "    \"\"\"Add season column based on lat and month\n",
    "    \"\"\"\n",
    "    site = df['site'].cat.categories.item()\n",
    "    lat = metadata[metadata['site'] == site]['lat'].item()\n",
    "    if lat > 0:\n",
    "        seasons = {3: 'spring',  4: 'spring',  5: 'spring',\n",
    "                   6: 'summer',  7: 'summer',  8: 'summer',\n",
    "                   9: 'fall',   10: 'fall',   11: 'fall',\n",
    "                  12: 'winter',  1: 'winter',  2: 'winter'}\n",
    "    else:\n",
    "        seasons = {3: 'fall',    4: 'fall',    5: 'fall',\n",
    "                   6: 'winter',  7: 'winter',  8: 'winter',\n",
    "                   9: 'spring', 10: 'spring', 11: 'spring',\n",
    "                  12: 'summer',  1: 'summer',  2: 'summer'}\n",
    "    return df.assign(season=df.TIMESTAMP.dt.month.map(seasons))\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    \"\"\"\n",
    "    Clean data columns:\n",
    "\n",
    "    * add NaN col for missing columns\n",
    "    * throw away un-needed columns\n",
    "    * add day of year\n",
    "    \"\"\"\n",
    "    df = df.assign(**{col: np.nan for col in keep_from_csv if col not in df.columns})\n",
    "    df = df[keep_from_csv]\n",
    "\n",
    "    df = df.assign(DOY=df.TIMESTAMP.dt.dayofyear)\n",
    "    df = df.assign(year=df.TIMESTAMP.dt.year)\n",
    "    df = season(df, metadata)\n",
    "\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Read and clean data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from s3fs import S3FileSystem\n",
    "\n",
    "s3 = S3FileSystem(anon=True)\n",
    "s3_paths = s3.glob('earth-data/carbon_flux/nee_data_fusion/FLX*')\n",
    "\n",
    "datasets = []\n",
    "skipped = []\n",
    "used = []\n",
    "\n",
    "for i, s3_path in enumerate(s3_paths):\n",
    "    dd = cat.fluxnet_daily(s3_path=s3_path).to_dask()\n",
    "    site = dd['site'].cat.categories.item()\n",
    "\n",
    "    if not set(dd.columns) >= set(data_columns):\n",
    "        skipped.append(site)\n",
    "        continue\n",
    "\n",
    "    datasets.append(clean_data(dd))\n",
    "    used.append(site)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = dask.dataframe.concat(datasets).compute()\n",
    "data.columns\n",
    "\n",
    "data['site'] = data['site'].astype('category')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualizing Data Available at Sites"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def mapper(x):\n",
    "    if x in used:\n",
    "        return 'valid'\n",
    "    elif x in skipped:\n",
    "        return 'skipped'\n",
    "    else:\n",
    "        return 'no data'\n",
    "\n",
    "cmap = {'valid': 'green', 'skipped': 'red', 'no data': 'darkgray'}\n",
    "\n",
    "QA = metadata.copy()\n",
    "QA['quality'] = QA['site'].map(mapper)\n",
    "\n",
    "all_points = QA.hvplot.points('lon', 'lat', geo=True, color='quality',\n",
    "                              cmap=cmap, hover_cols=['site', 'vegetation'],\n",
    "                              height=420, width=600).options(tools=['hover', 'tap'],\n",
    "                                                             legend_position='top')\n",
    "\n",
    "def veg_count(data):\n",
    "    veg_count = data['vegetation'].value_counts().sort_index(ascending=False)\n",
    "    return veg_count.hvplot.barh(height=420, width=500)\n",
    "\n",
    "hist = veg_count(QA[QA.quality=='valid']).relabel('Vegetation counts for valid sites')\n",
    "\n",
    "all_points * gts.OSM + hist"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll make a couple of functions that generate plots on the full set of data or a subset of the data. We will use these in a dashboard below."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def site_timeseries(data):\n",
    "    \"\"\"Timeseries plot showing the mean carbon flux at each DOY as well as the min and max\"\"\"\n",
    "\n",
    "    tseries = hv.Overlay([\n",
    "        (data.groupby(['DOY', 'year'])[y_variable]\n",
    "             .mean().groupby('DOY').agg([np.min, np.max])\n",
    "             .hvplot.area('DOY', 'amin', 'amax', alpha=0.2, fields={'amin': y_variable})),\n",
    "        data.groupby('DOY')[y_variable].mean().hvplot()])\n",
    "\n",
    "    return tseries.options(width=800, height=400)\n",
    "\n",
    "def site_count_plot(data):\n",
    "    \"\"\"Plot of the number of observations of each of the non-mandatory variables.\"\"\"\n",
    "    return data[soil_data_columns + ['site']].count().hvplot.bar(rot=90, width=300, height=400)\n",
    "\n",
    "timeseries = site_timeseries(data)\n",
    "count_plot = site_count_plot(data)\n",
    "timeseries + count_plot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}